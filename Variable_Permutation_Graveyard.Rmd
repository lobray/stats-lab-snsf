---
title: "Variable Permutation Graveyard"
author: "Leslie O'Bray"
date: "May 24, 2018"
output: pdf_document
---


```{r confidence intervals logistic external}
plot(0,xlim=c(-6,9), yaxt="n", pch="", ylim=c(0,32), main=paste0("Confidence Intervals Plot \n", "External Step"), ylab="",xlab="")
abline(v=0)
axis(2,1:dim(CI)[1], rownames(CI), las = 1, cex.axis=0.5)
for (i in 1:length(coef.log)) {
  interval <- c(CI[i,1], CI[i,2])
  col <- "black"
  if (interval[1] > 0 & 0 < interval[2]) {col="red"}
  lines(interval, c(i,i),col=col)
}
```



```{r CI clm project}
CI.project <- confint(Model.Prop)
plot(0,0,xlim=c(-1.5,1.5), pch="",yaxt="n", ylim=c(0,nrow(CI.project)), main="Confidence Intervals Plot", ylab="",xlab="")
abline(v=0)
axis(2,1:nrow(CI.project), rownames(CI.project), las = 1, cex.axis=0.6)
for (i in 1:nrow(CI.project)) {
  interval <- c(CI.project[i,1], CI.project[i,2])
  col <- "black"
  if (interval[1] > 0 & 0 < interval[2]) {col="red"}
  if (interval[1] < 0 & 0 > interval[2]) {col="red"}
  lines(interval, c(i,i),col=col)
}
```


```{r ex CI clm track}
CI.App <- confint(Model.App)
plot(0,0,xlim=c(-2,1.5), pch="",yaxt="n", ylim=c(0,nrow(CI.App)), main="Confidence Intervals Plot", ylab="",xlab="")
abline(v=0)
axis(2,1:nrow(CI.App), rownames(CI.App), las = 1, cex.axis=0.6)
for (i in 1:nrow(CI.App)) {
  interval <- c(CI.App[i,1], CI.App[i,2])
  col <- "black"
  if (interval[1] > 0 & 0 < interval[2]) {col="red"}
  if (interval[1] < 0 & 0 > interval[2]) {col="red"}
  lines(interval, c(i,i),col=col)
}
```

```{r ex CI clm OverallGrade}
CI.Overall <- confint(Model.Overall)
plot(0,0,xlim=c(-2,1.5), pch="",yaxt="n", ylim=c(0,nrow(CI.Overall)), main="Confidence Intervals Plot", ylab="",xlab="")
abline(v=0)
axis(2,1:nrow(CI.Overall), rownames(CI.Overall), las = 1, cex.axis=0.6)
for (i in 1:nrow(CI.Overall)) {
  interval <- c(CI.Overall[i,1], CI.Overall[i,2])
  col <- "black"
  if (interval[1] > 0 & 0 < interval[2]) {col="red"}
  if (interval[1] < 0 & 0 > interval[2]) {col="red"}
  lines(interval, c(i,i),col=col)
}
```


# Gender Bias


Finally, we estimated the relative importance of each of the predictors in the model as a last check, in order to see the importance of gender in all the models.

## External

In order to understand which of the variables in this model are the more influential, we ran a permutation test. We randomly permuted the values of all predictors (one at the time) and refit the the model. We did this 1000 times for each predictor, and calculated the average change in pseudo R^2 when we permuted that particular variable. If permuting a variable changes the pseudo r^2 a lot, this means that that variable was an important predictor in our regression. As shown in the next table, Gender is the second least important variable in this model.

We did also here our permutation test where we permuted each variable 1000 times, and used the percentage of variation of the AIC as a measure of good fit. Gender is the least important variable, in average it increments the AIC `r round(Shuffle.Result.Prop[6,3],2)`%.

Though, gender is significant to the model, when estimating its relative importance in comparison with the other variables, by permuting each variable 1000 times, and using the average percent variation on the AIC as a measure of goodness of fit, turns out that gender is the least important variable in the model, in average it increments the AIC `r round(Shuffle.Result.App[6,3],2)`%.

Again, we estimate the relative importance of the variables base on the percentage change of the AIC when permuting the variable. We did this permutation 1000 times for each variable. Gender is the second least important variable in the model, in average it increments the AIC `r round(Ov.Shuffle.Result[4,3],2)`%. 



```{r Logistic-external-relative-importance, out.width='50%',fig.align="center"}
# Relative variable importance 
# 
#   load("Ext.logistic_variable_importance.Rda")
#   kable(PseudoRShuffle,"latex", booktabs = T) %>%
#     kable_styling(position = "center")
# 
#   n<-dim(PseudoRShuffle)[1]
#   PseudoRShuffle$Importance<-abs(PseudoRShuffle$Importance)
#   mycol=colorRampPalette(c("blue","red"))(n)
# 
# #   par(las=2,mfrow=c(1,1),mai=c(1,2,1,1))
#   # barplot(PseudoRShuffle[,2], names.arg = PseudoRShuffle[,1],
#   #         horiz = TRUE,col = mycol,cex.names = 0.7,
#   #         main="Variable Importance for Approval",
#   #         xlab = "Percent of variation on the Pseudo R",
#   #         cex.axis = 0.6,
#   #         cex.main=0.8)
```

 Nevertheless we kept gender as a predictor to be able to show the effect it has in the grades. For this purpose we estimated the cumulative probability of falling in the different grades for each gende. The result is presented in the next table. Overall the average difference is `r round(mean(abs(gender.prob[,3])),5)`. We see here as well, that there is no evidence of gender influencing the probability of achiving a certain grade.
```{r out.width='50%',fig.align="center"}
# kable(gender.prob,"latex", booktabs = T) %>%
#     kable_styling(position = "center")
# 
# ggplot(gender.prob) +
#           geom_line(aes(1:6, Male, colour = "Male")) +
#           geom_line(aes(1:6, Female, colour = "Female"))+
#           theme(legend.title=element_blank(),legend.position = "bottom")+
#           xlab("")+ylab("Cumulative Probability")+
#           ggtitle("Cumulative Probability for ProposalCombined")
# ```
# ```{r}
# load("External_Project_variable_Importance.Rda")
```



    
```{r out.width='50%', fig.align="center"}
# kable(Shuffle.Result.Prop,"latex", booktabs = T) %>%
#     kable_styling(position = "center")
# 
# n<-dim(Shuffle.Result.Prop)[1] 
# mycol=colorRampPalette(c("red","green"))(n)
#        par(las=2)
       # barplot(Shuffle.Result.Prop[,3], names.arg = Shuffle.Result.Prop[,1],
       #         horiz = TRUE,col = mycol,cex.names = 0.7,
       #         main="Variable Importance of Combined Project Assessment",
       #         xlab = "Percent of variation on the AIC",
       #         xlim=c(0,0.7),
       #         cex.axis = 0.6,
       #         cex.main=0.8)
```


```{r}
kable(coeff<-round(summary(Model.App)$coefficients,4),"latex", booktabs = T)%>%
    kable_styling(position = "center")
```

```{r}

gender.prob.App<-Effect("Gender", mod=Model.App)
gender.prob.App<-gender.prob.App$prob
gender.prob.App<-data.frame(Male=gender.prob.App[1,],Female=gender.prob.App[2,])
rownames(gender.prob.App)<-c("poor","average","good", "very good",
                        "excellent","outstanding")

gender.prob.App<-cbind(round(gender.prob.App,3),Difference=round((gender.prob.App[,1]-gender.prob.App[,2]),3))
       
```
The predicted probabilities of achieving certain grade for male and female is shown in the next table. The average difference of the cumulative probability is here as well close to zero,`r round(mean(abs(gender.prob.App[,3])),5)`,  but the greater difference are in grades "outstanding", which are the ones that are more likely to be approved. 
```{r out.width='50%',fig.align="center"}
kable(gender.prob.App,"latex", booktabs = T) %>%
    kable_styling(position = "center")

ggplot(gender.prob.App) +
          geom_line(aes(1:6, Male, colour = "Male")) +
          geom_line(aes(1:6, Female, colour = "Female"))+
          theme(legend.title=element_blank(),legend.position = "bottom")+
          xlab("")+ylab("Cumulative Probability")+
          ggtitle("Cumulative Probability for Applicant Track")
```
```{r}
load("External_Applicant_variable_importance.Rda")
```

    
```{r out.width='50%', fig.align="center"}
# kable(Shuffle.Result.App,"latex", booktabs = T) %>%
#     kable_styling(position = "center")
# 
# n<-dim(Shuffle.Result.App)[1] 
# mycol=colorRampPalette(c("red","blue"))(n)
#        par(las=2)
       # barplot(Shuffle.Result.App[,3], names.arg = Shuffle.Result.App[,1],
       #         horiz = TRUE,col = mycol,cex.names = 0.7,
       #         main="Variable Importance of Applicant Assessment",
       #         xlab = "Percent of variation on the AIC",
       #         xlim = c(0,1.2), 
       #         cex.axis = 0.6,
       #         cex.main=0.8)
```


```{r}
load("External_Overall_variable_importance.Rda")
```

    
```{r out.width='50%', fig.align="center"}
# kable(Ov.Shuffle.Result,"latex", booktabs = T) %>%
#     kable_styling(position = "center")
# 
# n<-dim(Ov.Shuffle.Result)[1] 
# mycol=colorRampPalette(c("red","blue"))(n)
#        par(las=2)
       # barplot(Ov.Shuffle.Result[,3], names.arg = Ov.Shuffle.Result[,1],
       #         horiz = TRUE,col = mycol,cex.names = 0.7,
       #         main="Variable Importance of Applicant Assessment",
       #         xlab = "Percent of variation on the AIC",
       #         cex.axis = 0.6,
       #         cex.main=0.8)
```


## Internal


We did also a further check through a permutation test, in order to better understand which of the variables are the most influencial in the model. We randomly permuted the values of all predictors (one by one) and refitted the model. We did this 1000 times for each predictor, and calculated the average change in pseudo R^2 when we permuted that particular variable. If permuting a variable reduces the pseudo R^2 a lot, this means that that variable was an important predictor in our regression. As shown in the next table, gender is the least important variable in the model and when we permute its values the pseudo R^2 increases slightly, which means that the model becomes a bit better than before.


We did again a permutation test: we shuffled each variable 1000 times and we used the percentage of variation of the AIC as a measure of goodness fit. Gender is the second least important variable in the model and permuting its values, on average, it makes the AIC increase by `r round(Shuffle.Result.Prop[6,3],2)`%.


  So we proceeded with our analysis estimating the relative importance of the variables included in the model. We used a permutation test, as before, and it turned out that gender is not at all an important variable in the model, in fact when we shuffle the values referring to the variable Gender the AIC doesn't increase.
  
  
Once more, though gender is significant to the model, when estimating its relative importance in comparison with the other variables, it turns out that gender is one of the least important variable in the model, in average it increments the AIC `r round(Shuffle.Result.R[5,3],2)`%.

# Relative Importance


In each of these two regressions, we again computed the variable importance by permuting the values of the predictors one at a time. Since it is an Ordinal Regression, and there is no R^2 equivalent to measure the goodness of fit, we assessed goodness of fit based on the percent of variation in the AIC, another measure of goodness of fit. For both the external and the internal step, we found permuting the grade given to the Scientific Proposal by far had the biggest impact on the quality of the regression. This led us to conclude that the grade given to the Scientific Proposal far outweighs the grade given to the Applicant Track Record, or any of the demographic predictors, in explaining the overall grade given to an application.

## Internal


To assess the importance of each variable we performed a permutation test, shuffling the value of one variable at a time and computing the average variation in AIC. As you can see from the plot below, the Project Asessment is by far the most important variable to determine the internal Ranking.

```{r, include=F, message=F, warning=F}
  load("Internal_criteria_importance.Rda")
```

```{r out.width='50%', fig.align="center"}
kable(Shuffle.Result,"latex", booktabs = T) %>%
    kable_styling(position = "center")

n<-dim(Shuffle.Result)[1] 
mycol=colorRampPalette(c("red","blue"))(n)
       par(las=2)
       barplot(Shuffle.Result[,3], names.arg = Shuffle.Result[,1],
               horiz = TRUE,col = mycol,cex.names = 0.7,
               main="Variable Importance to establish Ranking",
               xlab = "Percent of variation on the AIC",
               xlim = c(0,115), 
               cex.axis = 0.6,
               cex.main=0.8)
```

When we permutRanking Probability vs Track Recorde the Project Assessment grades, the AIC increases by `r round(Shuffle.Result[8,3],2)`%. The second most important variable is the Applicant Track, but shuffling its values the AIC increases by "only" `r round(Shuffle.Result.R[7,3],2)`%.

## External